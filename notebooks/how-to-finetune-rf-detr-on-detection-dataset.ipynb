{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eroxpm/Deep-Learning/blob/main/notebooks/how-to-finetune-rf-detr-on-detection-dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[![Roboflow Notebooks](https://media.roboflow.com/notebooks/template/bannertest2-2.png?ik-sdk-version=javascript-1.4.3&updatedAt=1672932710194)](https://github.com/roboflow/notebooks)\n",
        "\n",
        "# How to Train RF-DETR Object Detection on a Custom Dataset\n",
        "\n",
        "---\n",
        "\n",
        "[![hf space](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue)](https://huggingface.co/spaces/SkalskiP/RF-DETR)\n",
        "[![colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/roboflow-ai/notebooks/blob/main/notebooks/how-to-finetune-rf-detr-on-detection-dataset.ipynb)\n",
        "[![roboflow](https://raw.githubusercontent.com/roboflow-ai/notebooks/main/assets/badges/roboflow-blogpost.svg)](https://blog.roboflow.com/rf-detr)\n",
        "[![code](https://badges.aleen42.com/src/github.svg)](https://github.com/roboflow/rf-detr)\n",
        "\n",
        "RF-DETR is a real-time, transformer-based object detection model architecture developed by Roboflow and released under the Apache 2.0 license.\n",
        "\n",
        "![rf-detr-coco-rf100-vl-8](https://media.roboflow.com/rf-detr/charts.png)\n",
        "\n",
        "RF-DETR is the first real-time model to exceed 60 AP on the [Microsoft COCO benchmark](https://cocodataset.org/#home) alongside competitive performance at base sizes. It also achieves state-of-the-art performance on [RF100-VL](https://github.com/roboflow/rf100-vl), an object detection benchmark that measures model domain adaptability to real world problems. RF-DETR is comparable speed to current real-time objection models.\n",
        "\n",
        "![rf-detr-coco-results-2](https://media.roboflow.com/rf-detr/example_grid.png)\n",
        "\n",
        "RF-DETR is small enough to run on the edge, making it an ideal model for deployments that need both strong accuracy and real-time performance."
      ],
      "metadata": {
        "id": "ww8fUIQ8SY2U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Environment setup"
      ],
      "metadata": {
        "id": "qhxdEkemS29m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configure API keys\n",
        "\n",
        "To fine-tune RF-DETR, you need to provide your Roboflow API key. Follow these steps:\n",
        "\n",
        "- Open your [`HuggingFace Settings`](https://huggingface.co/settings) page. Click `Access Tokens` then `New Token` to generate new token.\n",
        "- Go to your [`Roboflow Settings`](https://app.roboflow.com/settings/api) page. Click `Copy`. This will place your private key in the clipboard.\n",
        "- In Colab, go to the left pane and click on `Secrets` (ðŸ”‘).\n",
        "    - Store HuggingFace Access Token under the name `HF_TOKEN`.\n",
        "    - Store Roboflow API Key under the name `ROBOFLOW_API_KEY`."
      ],
      "metadata": {
        "id": "rT5h00v0TN54"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "#os.environ[\"HF_TOKEN\"] = userdata.get(\"HF_TOKEN\")\n",
        "os.environ[\"ROBOFLOW_API_KEY\"] = userdata.get(\"ROBOFLOW_API_KEY\")"
      ],
      "metadata": {
        "id": "_dGO4a7eTbFX",
        "outputId": "891b966c-a82e-4847-e111-3b096af151cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SecretNotFoundError",
          "evalue": "Secret HF_TOKEN does not exist.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mSecretNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-defa0cab2495>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"HF_TOKEN\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"HF_TOKEN\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ROBOFLOW_API_KEY\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ROBOFLOW_API_KEY\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/userdata.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'exists'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mSecretNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'access'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mNotebookAccessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSecretNotFoundError\u001b[0m: Secret HF_TOKEN does not exist."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check GPU availability\n",
        "\n",
        "Let's make sure that we have access to GPU. We can use `nvidia-smi` command to do that. In case of any problems navigate to `Edit` -> `Notebook settings` -> `Hardware accelerator`, set it to `T4 GPU`, and then click `Save`."
      ],
      "metadata": {
        "id": "iwzfrPKyTqDc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "ms0ps6ZCT2xs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install dependencies"
      ],
      "metadata": {
        "id": "JSbiL1I6T8JY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q rfdetr==1.1.0"
      ],
      "metadata": {
        "id": "3CbzMY6wITlr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download example data"
      ],
      "metadata": {
        "id": "hzulEARVVZxw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://media.roboflow.com/notebooks/examples/dog-2.jpeg\n",
        "!wget -q https://media.roboflow.com/notebooks/examples/dog-3.jpeg"
      ],
      "metadata": {
        "id": "8DCCwexcU6gO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference with Pre-trained COCO Model"
      ],
      "metadata": {
        "id": "wGfBHjJwWNEO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from rfdetr import RFDETRBase\n",
        "from rfdetr.util.coco_classes import COCO_CLASSES\n",
        "import supervision as sv\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "image = Image.open(\"dog-2.jpeg\")\n",
        "\n",
        "model = RFDETRBase()\n",
        "detections = model.predict(image, threshold=0.5)\n",
        "\n",
        "color = sv.ColorPalette.from_hex([\n",
        "    \"#ffff00\", \"#ff9b00\", \"#ff8080\", \"#ff66b2\", \"#ff66ff\", \"#b266ff\",\n",
        "    \"#9999ff\", \"#3399ff\", \"#66ffff\", \"#33ff99\", \"#66ff66\", \"#99ff00\"\n",
        "])\n",
        "text_scale = sv.calculate_optimal_text_scale(resolution_wh=image.size)\n",
        "thickness = sv.calculate_optimal_line_thickness(resolution_wh=image.size)\n",
        "\n",
        "bbox_annotator = sv.BoxAnnotator(color=color, thickness=thickness)\n",
        "label_annotator = sv.LabelAnnotator(\n",
        "    color=color,\n",
        "    text_color=sv.Color.BLACK,\n",
        "    text_scale=text_scale,\n",
        "    smart_position=True\n",
        ")\n",
        "\n",
        "labels = [\n",
        "    f\"{COCO_CLASSES[class_id]} {confidence:.2f}\"\n",
        "    for class_id, confidence\n",
        "    in zip(detections.class_id, detections.confidence)\n",
        "]\n",
        "\n",
        "annotated_image = image.copy()\n",
        "annotated_image = bbox_annotator.annotate(annotated_image, detections)\n",
        "annotated_image = label_annotator.annotate(annotated_image, detections, labels)\n",
        "annotated_image"
      ],
      "metadata": {
        "id": "PtOufRspVekp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download dataset from Roboflow Universe"
      ],
      "metadata": {
        "id": "MK6zkzY1lPtw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from roboflow import download_dataset\n",
        "\n",
        "dataset = download_dataset(\"https://universe.roboflow.com/rf100-vl/mahjong-vtacs-mexax-m4vyu-sjtd/dataset/2\", \"coco\")"
      ],
      "metadata": {
        "id": "hQkMUyB0lROT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train RF-DETR on custom dataset\n",
        "\n",
        "### Choose the right `batch_size`\n",
        "\n",
        "Different GPUs have different amounts of VRAM (video memory), which limits how much data they can handle at once during training. To make training work well on any machine, you can adjust two settings: `batch_size` and `grad_accum_steps`. These control how many samples are processed at a time. The key is to keep their product equal to 16 â€” thatâ€™s our recommended total batch size. For example, on powerful GPUs like the A100, set `batch_size=16` and `grad_accum_steps=1`. On smaller GPUs like the T4, use `batch_size=4` and `grad_accum_steps=4`. We use a method called gradient accumulation, which lets the model simulate training with a larger batch size by gradually collecting updates before adjusting the weights.\n",
        "\n",
        "### Train with multiple GPUs\n",
        "\n",
        "You can fine-tune RF-DETR on multiple GPUs using PyTorchâ€™s Distributed Data Parallel (DDP). Create a `main.py` script that initializes your model and calls `.train()` as usual than run it in terminal.\n",
        "\n",
        "```bash\n",
        "python -m torch.distributed.launch \\\n",
        "    --nproc_per_node=8 \\\n",
        "    --use_env \\\n",
        "    main.py\n",
        "```\n",
        "\n",
        "Replace `8` in the `--nproc_per_node argument` with the number of GPUs you want to use. This approach creates one training process per GPU and splits the workload automatically. Note that your effective batch size is multiplied by the number of GPUs, so you may need to adjust your `batch_size` and `grad_accum_steps` to maintain the same overall batch size."
      ],
      "metadata": {
        "id": "vmT8f_bAq3zX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from rfdetr import RFDETRBase\n",
        "\n",
        "model = RFDETRBase()\n",
        "\n",
        "model.train(dataset_dir=dataset.location, epochs=15, batch_size=16, grad_accum_steps=1, lr=1e-4)"
      ],
      "metadata": {
        "id": "1UvmuIammK9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "Image.open(\"/content/output/metrics_plot.png\")"
      ],
      "metadata": {
        "id": "65A4MXYtB94O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run inference with fine-tuned model"
      ],
      "metadata": {
        "id": "xT1tPwZS_-6t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import supervision as sv\n",
        "\n",
        "ds = sv.DetectionDataset.from_coco(\n",
        "    images_directory_path=f\"{dataset.location}/test\",\n",
        "    annotations_path=f\"{dataset.location}/test/_annotations.coco.json\",\n",
        ")"
      ],
      "metadata": {
        "id": "xm-lmRWLswO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from rfdetr import RFDETRBase\n",
        "import supervision as sv\n",
        "from PIL import Image\n",
        "\n",
        "path, image, annotations = ds[0]\n",
        "image = Image.open(path)\n",
        "\n",
        "detections = model.predict(image, threshold=0.5)\n",
        "\n",
        "text_scale = sv.calculate_optimal_text_scale(resolution_wh=image.size)\n",
        "thickness = sv.calculate_optimal_line_thickness(resolution_wh=image.size)\n",
        "\n",
        "bbox_annotator = sv.BoxAnnotator(thickness=thickness)\n",
        "label_annotator = sv.LabelAnnotator(\n",
        "    text_color=sv.Color.BLACK,\n",
        "    text_scale=text_scale,\n",
        "    text_thickness=thickness,\n",
        "    smart_position=True)\n",
        "\n",
        "annotations_labels = [\n",
        "    f\"{ds.classes[class_id]}\"\n",
        "    for class_id\n",
        "    in annotations.class_id\n",
        "]\n",
        "\n",
        "detections_labels = [\n",
        "    f\"{ds.classes[class_id]} {confidence:.2f}\"\n",
        "    for class_id, confidence\n",
        "    in zip(detections.class_id, detections.confidence)\n",
        "]\n",
        "\n",
        "annotation_image = image.copy()\n",
        "annotation_image = bbox_annotator.annotate(annotation_image, annotations)\n",
        "annotation_image = label_annotator.annotate(annotation_image, annotations, annotations_labels)\n",
        "\n",
        "detections_image = image.copy()\n",
        "detections_image = bbox_annotator.annotate(detections_image, detections)\n",
        "detections_image = label_annotator.annotate(detections_image, detections, detections_labels)\n",
        "\n",
        "sv.plot_images_grid(images=[annotation_image, detections_image], grid_size=(1, 2), titles=[\"Annotation\", \"Detection\"])"
      ],
      "metadata": {
        "id": "msor_5HgAkm3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import supervision as sv\n",
        "from rfdetr import RFDETRBase\n",
        "from PIL import Image\n",
        "\n",
        "detections_images = []\n",
        "\n",
        "for i in range(9):\n",
        "    path, image, annotations = ds[i]\n",
        "    image = Image.open(path)\n",
        "\n",
        "    detections = model.predict(image, threshold=0.5)\n",
        "\n",
        "    text_scale = sv.calculate_optimal_text_scale(resolution_wh=image.size)\n",
        "    thickness = sv.calculate_optimal_line_thickness(resolution_wh=image.size)\n",
        "\n",
        "    bbox_annotator = sv.BoxAnnotator(thickness=thickness)\n",
        "    label_annotator = sv.LabelAnnotator(\n",
        "        text_color=sv.Color.BLACK,\n",
        "        text_scale=text_scale,\n",
        "        text_thickness=thickness,\n",
        "        smart_position=True)\n",
        "\n",
        "    detections_labels = [\n",
        "        f\"{ds.classes[class_id]} {confidence:.2f}\"\n",
        "        for class_id, confidence\n",
        "        in zip(detections.class_id, detections.confidence)\n",
        "    ]\n",
        "\n",
        "    detections_image = image.copy()\n",
        "    detections_image = bbox_annotator.annotate(detections_image, detections)\n",
        "    detections_image = label_annotator.annotate(detections_image, detections, detections_labels)\n",
        "\n",
        "    detections_images.append(detections_image)\n",
        "\n",
        "sv.plot_images_grid(images=detections_images, grid_size=(3, 3), size=(12, 12))"
      ],
      "metadata": {
        "id": "RFEgIOz1YDCe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate fine-tuned model"
      ],
      "metadata": {
        "id": "X_9c113E39QP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import supervision as sv\n",
        "from tqdm import tqdm\n",
        "from supervision.metrics import MeanAveragePrecision\n",
        "\n",
        "targets = []\n",
        "predictions = []\n",
        "\n",
        "for path, image, annotations in tqdm(ds):\n",
        "    image = Image.open(path)\n",
        "    detections = model.predict(image, threshold=0.5)\n",
        "\n",
        "    targets.append(annotations)\n",
        "    predictions.append(detections)"
      ],
      "metadata": {
        "id": "szxs3PZsBVxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "map_metric = MeanAveragePrecision()\n",
        "map_result = map_metric.update(predictions, targets).compute()\n",
        "\n",
        "map_result.plot()"
      ],
      "metadata": {
        "id": "fxqvXOQcsRF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix = sv.ConfusionMatrix.from_detections(\n",
        "    predictions=predictions,\n",
        "    targets=targets,\n",
        "    classes=ds.classes\n",
        ")\n",
        "\n",
        "confusion_matrix.plot()"
      ],
      "metadata": {
        "id": "WuiNB-UM1xsJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}